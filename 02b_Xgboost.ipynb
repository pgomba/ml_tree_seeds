{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files in output to use\n",
    "target_in_output = (\"outputs/XGBoost\")\n",
    "#seed data folder\n",
    "seed_data=(\"data/ml_paper_seeds_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "species=[\"Alnus_glutinosa\",\"Betula_pendula\",\"Betula_pubescens\",\"Pinus_sylvestris\",\"Sorbus_aucuparia\",\"all_species\"]\n",
    "folders=[\"names_all_features\",\"names_colour_features\",\"names_xray_features\"]\n",
    "\n",
    "feature_sets = {\n",
    "    \"names_all_features\": [\"Area\", \"Perim.\", \"Feret\", \"MinFeret\", \"Circ.\", \"AR\", \"Round\", \"Solidity\", \"Mean_L\", \"Mean_a\", \"Mean_b\", \"Mean_grey\", \"Mean_core_grey\", \"Dissimilarity\", \"Contrast\", \"Homogeneity\", \"Energy\", \"Correlation\", \"ASM\", \"Bin_germ\"],\n",
    "    \"names_colour_features\": [\"Area\", \"Perim.\", \"Feret\", \"MinFeret\", \"Circ.\", \"AR\", \"Round\", \"Solidity\", \"Mean_L\", \"Mean_a\", \"Mean_b\", \"Dissimilarity\", \"Contrast\", \"Homogeneity\", \"Energy\", \"Correlation\", \"ASM\", \"Bin_germ\"],\n",
    "    \"names_xray_features\": [\"Mean_grey\", \"Mean_core_grey\", \"Bin_germ\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975, Precision: 0.974, f1: 0.984, Recall: 0.993, AUC: 0.956, Specificity: 0.918\n",
      "Accuracy: 0.824, Precision: 0.805, f1: 0.873, Recall: 0.954, AUC: 0.777, Specificity: 0.600\n",
      "Accuracy: 0.739, Precision: 0.718, f1: 0.818, Recall: 0.951, AUC: 0.673, Specificity: 0.395\n",
      "Accuracy: 0.823, Precision: 0.810, f1: 0.883, Recall: 0.971, AUC: 0.735, Specificity: 0.500\n",
      "Accuracy: 0.915, Precision: 0.929, f1: 0.956, Recall: 0.984, AUC: 0.492, Specificity: 0.000\n",
      "Accuracy: 0.855, Precision: 0.860, f1: 0.905, Recall: 0.955, AUC: 0.773, Specificity: 0.591\n",
      "Accuracy: 0.751, Precision: 0.804, f1: 0.844, Recall: 0.888, AUC: 0.607, Specificity: 0.327\n",
      "Accuracy: 0.629, Precision: 0.661, f1: 0.745, Recall: 0.854, AUC: 0.547, Specificity: 0.240\n",
      "Accuracy: 0.668, Precision: 0.673, f1: 0.771, Recall: 0.902, AUC: 0.596, Specificity: 0.289\n",
      "Accuracy: 0.763, Precision: 0.783, f1: 0.840, Recall: 0.904, AUC: 0.678, Specificity: 0.452\n",
      "Accuracy: 0.925, Precision: 0.930, f1: 0.961, Recall: 0.995, AUC: 0.497, Specificity: 0.000\n",
      "Accuracy: 0.756, Precision: 0.768, f1: 0.850, Recall: 0.951, AUC: 0.597, Specificity: 0.243\n",
      "Accuracy: 0.980, Precision: 0.974, f1: 0.987, Recall: 1.000, AUC: 0.959, Specificity: 0.918\n",
      "Accuracy: 0.805, Precision: 0.792, f1: 0.859, Recall: 0.938, AUC: 0.756, Specificity: 0.573\n",
      "Accuracy: 0.709, Precision: 0.710, f1: 0.791, Recall: 0.894, AUC: 0.651, Specificity: 0.408\n",
      "Accuracy: 0.818, Precision: 0.801, f1: 0.881, Recall: 0.978, AUC: 0.723, Specificity: 0.468\n",
      "Accuracy: 0.930, Precision: 0.930, f1: 0.964, Recall: 1.000, AUC: 0.500, Specificity: 0.000\n",
      "Accuracy: 0.845, Precision: 0.838, f1: 0.901, Recall: 0.974, AUC: 0.739, Specificity: 0.504\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "\n",
    "# Filter out 'Bin_germ' from the list of features for feature importance\n",
    "filtered_features = [\"Area\", \"Perim.\", \"Feret\", \"MinFeret\", \"Circ.\", \"AR\", \"Round\", \"Solidity\", \"Mean_L\", \"Mean_a\", \"Mean_b\", \"Mean_grey\", \"Mean_core_grey\", \"Dissimilarity\", \"Contrast\", \"Homogeneity\", \"Energy\", \"Correlation\", \"ASM\"]\n",
    "\n",
    "\n",
    "for folder in folders:\n",
    "    all_yhat = []\n",
    "    for specie in species:\n",
    "        # Combine species and features here\n",
    "        combined_path = os.path.join(target_in_output,specie, folder, \"cv_model.dat\")\n",
    "        \n",
    "        # Load data from data.dat\n",
    "        with open(combined_path, 'rb') as file:\n",
    "            loaded_model = pickle.load(file)\n",
    "                \n",
    "        # Use the loaded data as needed, for example, print it\n",
    "        #print(f\"Data for {specie} in {folder}: {loaded_model}\")\n",
    "\n",
    "        features = feature_sets.get(folder, [])\n",
    "            \n",
    "        seeds_all_data = pd.read_csv(seed_data)\n",
    "        seeds_sp = seeds_all_data[seeds_all_data.Species == specie] \n",
    "        seeds = seeds_sp[seeds_sp.Set == \"train\"] \n",
    "        seeds = seeds[features]\n",
    "        X, y = seeds[seeds.columns.tolist()[:-1]], seeds[seeds.columns.tolist()[-1]]\n",
    "        X = X.to_numpy() #RDCOMM if you leave it as a Pandas df, the model still runs and the features keep their names for feature importances (win win!)\n",
    "        y = y.to_numpy()\n",
    "        holdout = seeds_sp[seeds_sp.Set == \"Hold out\"] \n",
    "        holdout = holdout[features]\n",
    "        X_test, y_test = holdout[holdout.columns.tolist()[:-1]], holdout[holdout.columns.tolist()[-1]]\n",
    "        X_test = X_test.to_numpy()\n",
    "        y_test = y_test.to_numpy()\n",
    "\n",
    "        yhat = loaded_model.predict(X_test)\n",
    "        yhat_probs = loaded_model.predict_proba(X_test)[:, 1] # Probability of positive class to calculate AUC, but I think in this case it is the same as yhat. Probably the threshold has already been applied.\n",
    "        #evaluate the model\n",
    "        acc = accuracy_score(y_test, yhat)\n",
    "        prec = precision_score(y_test, yhat)\n",
    "        f1 = f1_score(y_test, yhat)\n",
    "        rec = recall_score(y_test, yhat) #same as sensitivity\n",
    "        auc = roc_auc_score(y_test, yhat_probs) #AUC improves considerably when XGBClassifier(objective = 'binary:logistic')\n",
    "\n",
    "        # Calculate specificity\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, yhat).ravel()\n",
    "        specif = tn / (tn + fp)\n",
    "\n",
    "        cm = confusion_matrix(y_test, yhat)\n",
    "\n",
    "        ### RDCOMM: changed from here\n",
    "        # results_list.append({'Species':specie, 'model':folder, 'Accuracy': acc, 'Precision': prec, 'f1': f1,'Recall':rec,'AUC':auc,'Specificity':specif,'cm_tl':cm[0][0],\n",
    "        #                      'cm_tr':cm[0][1],'cm_bl':cm[1][0],'cm_br':cm[1][1]})\n",
    "\n",
    "        fi_gain = loaded_model.best_estimator_.get_booster().get_score(importance_type='gain')\n",
    "        fi_weight = loaded_model.best_estimator_.get_booster().get_score(importance_type='weight')\n",
    "\n",
    "        \n",
    "        # Would like to append the score from fi_gain and fi_weights to results_list. Note that not all models will have all features.\n",
    "        # Append results to the list\n",
    "        results_dict = {\n",
    "            'Species': specie,\n",
    "            'model': folder,\n",
    "            'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'f1': f1,\n",
    "            'Recall': rec,\n",
    "            'AUC': auc,\n",
    "            'Specificity': specif,\n",
    "            'cm_TN_tl': cm[0][0],\n",
    "            'cm_FP_tr': cm[0][1],\n",
    "            'cm_FN_bl': cm[1][0],\n",
    "            'cm_TP_br': cm[1][1],\n",
    "        }\n",
    "\n",
    "        # Add feature importance scores to the results_dict (excluding 'Bin_germ')\n",
    "        results_dict.update({'fi_gain_' + str(feature): fi_gain.get(feature, 'NA') for feature in filtered_features})\n",
    "        results_dict.update({'fi_weight_' + str(feature): fi_weight.get(feature, 'NA') for feature in filtered_features})\n",
    "\n",
    "        results_list.append(results_dict)\n",
    "\n",
    "        print('Accuracy: %.3f, Precision: %.3f, f1: %.3f, Recall: %.3f, AUC: %.3f, Specificity: %.3f' % (acc, prec, f1, rec, auc, specif))\n",
    "\n",
    "        all_yhat.extend(yhat)\n",
    "    \n",
    "    results_test = pd.DataFrame({'Prediction': all_yhat})\n",
    "    output_file = f'Outputs/XGBoost/predictions_{folder}.csv'\n",
    "    results_test.to_csv(output_file, index=False)\n",
    "        \n",
    "\n",
    "final_df = pd.DataFrame(results_list)\n",
    "csv_filename = (\"outputs/XGBoost/evaluation_results.csv\")\n",
    "final_df.to_csv(csv_filename, index=False)          \n",
    "                    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_seeds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
